---
title: "Visualizing Robustness in Biomedical Data Analysis"
author: "<br><br><span style='font-size:25px;'><strong>Lesley Chapman Hannah, Ph.D., M.S.</strong></span><br>College of Graduate Studies<br>Northeast Ohio Medical University"

format: 
  revealjs:
    #theme: solarized
    css: style.css
    slide-number: true
    chalkboard: 
      buttons: false
    preview-links: auto
    logo: images/Flame.jpg
    #css: styles.css
    
---


## <span style="font-size:80%">Robustness in Data Analysis</span> {.smaller}

- Robustness: capacity of a model, analytic pipeline, or scientific conclusion to consistent behavior when exposed to variations and/or perturbations
- Variations can arise across the data science lifecycle, including: data acquisition, preprocessing, model development, validation, and real-world deployment
- Examples of types of variation:
  - missing or imbalanced data
  - uncertainty in labels
  - alternative feature extraction or selection strategies
  - shifts in patient populations
  
  
<span style="font-size:50%">Balendran, A., et. al. npj Digit. Med. 8, 38 (2025).</span>

::: footer

:::


## <span style="font-size:80%">Robustness in the Data Science Lifecycle</span> {.smaller}

- robustness: process by which analytic results and interpretations remain consistent as data are imported, structured, transformed, modeled, and communicated
- **import and tidy stages**: ability to maintain analytic results when variation in data acquisition, encoding, missingness might occur
- **transformation**: stability of preprocessing choices such as normalization, filtering, and thresholding that encode biological and clinical assumptions
- **model stage**: consistency of estimates and predictions across reasonable model specifications, training strategies, and validation contexts
- **communication**: robustness is conveyed as visual evidence supporting the scientific claim, with figures that make stability and sensitivity transparent
  
::: footer

:::

## <span style="font-size:80%">Robustness: Data Lifecycle - Import</span> {.smaller}

- Robustness: capacity of a model, analytic pipeline, or scientific conclusion to consistent behavior when exposed to variations and/or perturbations
- Maintaining robustness at the import stage might involve:
  - conclusions remain stable across representational differences
  - analytic pipeline absorbs operational variability
  - visualizations confirm consistency before modeling begins
  
- plots developed at the import stage supports robustness by revealing unit differences across sites which can help guide downstream harmonization  

<span style="font-size:50%">Balendran, A., et. al. npj Digit. Med. 8, 38 (2025).</span>

::: footer

:::

## <span style="font-size:80%">Example: Unit consistency supports robust inference</span> {.smaller}

`Scientific question`: Are lactate levels higher in sepsis cases than in controls?

**Data artifacts at import stage**:

- Hospital A reports lactate in mmol/L
- Hospital B reports lactate in mg/dL
- Biology is consistent across sites
- Units differ due to workflow choices

- Plots generated at the import stage can help clarify sources of variation 


::: footer

:::



<style>
.tiny-table table { font-size: 0.8em; }        /* adjust as needed (0.8–0.9em) */
.tiny-table figcaption, .tiny-table .table-caption { font-size: 0.75em; }
</style>

## <span style="font-size:60%">Example: Unit consistency supports robust inference</span> {.smaller}


::: columns
::: {.column .small}

**Plot Interpretation**

- Simulated biological data that introduces unit inconsistency at import to mimic data variability
- **left plot**: imported lactate values by site, revealing Hospital B’s values are about 9 times higher due to unit differences (mg/dL vs mmol/L)

- **middle and right plots**: 
  - lactate by sepsis status within each hospital
  - scales differ $\rightarrow$ making direct comparison misleading before unit harmonization

- plots highlight unit inconsistencies
- strategy: data harmonization before analysis
- data visualization can be used as a tool to evaluate robustness at the import stage 
- harmonization strategy : convert lactate units from mg/dL $\rightarrow$ mmol/L by dividing Hospital B’s lactate values by 9


:::
::: column

```{r}

set.seed(30)

# -----------------------------
# Simulate imported clinical data
# -----------------------------
n <- 300
data <- data.frame(
  site = sample(c("Hospital A", "Hospital B"), n, replace = TRUE),
  sepsis = factor(rbinom(n, 1, 0.5), labels = c("Control", "Sepsis"))
)

# True biological lactate signal (mmol/L)
true_lactate <- rlnorm(
  n,
  meanlog = 0.6 + 0.4 * (data$sepsis == "Sepsis"),
  sdlog = 0.5
)

# Unit variation introduced at import
data$lactate <- true_lactate
data$lactate[data$site == "Hospital B"] <-
  data$lactate[data$site == "Hospital B"] * 9

# -----------------------------
# Import-stage visualization
# -----------------------------
par(mfrow = c(1, 3))

boxplot(
  lactate ~ site,
  data = data,
  main = "Imported lactate by site",
  ylab = "Lactate (as imported)",
  col = c("lightblue", "salmon")
)

boxplot(
  lactate ~ sepsis,
  data = data[data$site == "Hospital A", ],
  main = "Hospital A",
  ylab = "Lactate",
  col = c("gray", "orange")
)

boxplot(
  lactate ~ sepsis,
  data = data[data$site == "Hospital B", ],
  main = "Hospital B",
  ylab = "Lactate",
  col = c("gray", "orange")
)

# -----------------------------
# Unit harmonization at import
# -----------------------------
data$lactate_mmol <- data$lactate
data$lactate_mmol[data$site == "Hospital B"] <-
  data$lactate_mmol[data$site == "Hospital B"] / 9

# -----------------------------
# Visualization after harmonization
# -----------------------------
#par(mfrow = c(1, 1))

#boxplot(
#  lactate_mmol ~ sepsis,
#  data = data,
#  main = "Lactate after unit harmonization",
#  ylab = "Lactate (mmol/L)",
#  col = c("gray", "orange")
#)

# -----------------------------
# Stability of inference
# -----------------------------
#summary(lm(lactate_mmol ~ sepsis + site, data = data))


```
:::
:::


<style>
.tiny-table table { font-size: 0.8em; }        /* adjust as needed (0.8–0.9em) */
.tiny-table figcaption, .tiny-table .table-caption { font-size: 0.75em; }
</style>



## <span style="font-size:80%">Data Transformation and Robustness</span> {.smaller}

- scientific conclusions remain consistent across different choices for normalization, filtering, and thresholding
- analytic pipelines produce stable effect estimates even when raw measurements are skewed or contain extreme values
- plots can be used as guides for transformation decisions 

Steps in transformation:

- **normalization**: log transforms, scaling
- **filtering**: exclude low-quality or undetectable values
- **thresholding**: apply limits of detection or clinical cutoffs

::: footer

:::

## <span style="font-size:80%">Biomarker data transformation and robust inference</span> {.smaller}

**Scientific question**

Are biomarker levels higher in disease cases than controls, and does this conclusion remain robust under different transformation choices?

**Simulated Data**

- **sample size**: 400 observations
- **groups**: Two groups labeled "Control" and "Disease", each with roughly equal numbers (randomly assigned)
- raw biomarker values


::: footer

:::


## <span style="font-size:80%">Biomarker data transformation and robust inference</span> {.smaller}

**Transformations Applied**:

1. `normalization (log transform)`:
 
    - applied log() to raw biomarker values to reduce skewness and make data more symmetric
    - helpful for improving downstream model interpretability

2. `scaling (z-score)`:

    - standardizes the log-transformed data to have mean zero and standard deviation one
    - useful for comparing effect sizes and stabilizing numerical computations
  
3. `filtering & thresholding`:

    - user definited limit of dectection [LOD]: 0.3
    - useful for comparing effect sizes and stabilizing numerical computations  
    - values below 0.3 are considered undetectable or unreliable and are set to NA (missing)

::: footer

:::


<style>
.tiny-table table { font-size: 0.8em; }        /* adjust as needed (0.8–0.9em) */
.tiny-table figcaption, .tiny-table .table-caption { font-size: 0.75em; }
</style>

## <span style="font-size:60%">Biomarker data transformation and robust inference</span> {.smaller}


::: columns
::: {.column .large}
Boxplots compare biomarker distributions by disease status:

  - **raw biomarker values**:  shows original skewed data with outliers.
  - **log-transformed biomarker**: shows more symmetric, normalized data.
  - **filtered raw data**: excludes low/undetectable values to focus on reliable measurements.
  - **log-transformed filtered data**: combines normalization and quality filtering.

:::
::: column

```{r}
#| fig-width: 8
#| fig-height: 9
#|
set.seed(50)

# -----------------------------
# Simulate raw biomarker data
# -----------------------------
n <- 400
data <- data.frame(
  disease = factor(rbinom(n, 1, 0.5), labels = c("Control", "Disease"))
)

data$biomarker_raw <- rlnorm(
  n,
  meanlog = 1 + 0.3 * (data$disease == "Disease"),
  sdlog = 0.7
)


data$biomarker_raw[sample(1:n, 30)] <- runif(30, 0.01, 0.2)

# -----------------------------
# Transformation stage
# -----------------------------

# 1. Normalization (log transform)
data$biomarker_log <- log(data$biomarker_raw)

# 2. Scaling (z-score)
data$biomarker_scaled <- scale(data$biomarker_log)

# 3. Filtering & thresholding
LOD <- 0.3  # limit of detection
data$biomarker_filtered <- ifelse(data$biomarker_raw >= LOD, data$biomarker_raw, NA)
data$biomarker_log_filtered <- ifelse(data$biomarker_raw >= LOD, data$biomarker_log, NA)

# -----------------------------
# Visualization: raw vs transformed vs filtered
# -----------------------------
par(mfrow = c(2, 2))

boxplot(
  biomarker_raw ~ disease,
  data = data,
  main = "Raw biomarker",
  ylab = "Biomarker",
  col = c("lightgray", "orange")
)

boxplot(
  biomarker_log ~ disease,
  data = data,
  main = "Log-transformed",
  ylab = "Log biomarker",
  col = c("lightgray", "orange")
)

boxplot(
  biomarker_filtered ~ disease,
  data = data,
  main = "Filtered (LOD)",
  ylab = "Biomarker >= 0.3",
  col = c("lightgray", "orange")
)

boxplot(
  biomarker_log_filtered ~ disease,
  data = data,
  main = "Log + Filtered",
  ylab = "Log biomarker >= LOD",
  col = c("lightgray", "orange")
)

# -----------------------------
# Check robustness of inference
# -----------------------------
#summary(lm(biomarker_raw ~ disease, data = data))
#summary(lm(biomarker_log ~ disease, data = data))
#summary(lm(biomarker_filtered ~ disease, data = data))
#summary(lm(biomarker_log_filtered ~ disease, data = data))

```
:::
:::


<style>
.tiny-table table { font-size: 0.8em; }        /* adjust as needed (0.8–0.9em) */
.tiny-table figcaption, .tiny-table .table-caption { font-size: 0.75em; }
</style>



## <span style="font-size:80%">Summary</span> {.smaller}

- robustness reflects whether scientific conclusions remain stable as data pass through the full data science lifecycle, including import, transformation, modeling, and communication
- variations and perturbations are expected properties of biomedical data, arising from missingness, label uncertainty, feature extraction choices, and population differences to list a few examples
- Visualization enables robustness to be directly inspected by comparing plots across perturbations, visualization reveals whether a scientific conclusion reflects stable biological signal
- independent discovery: communication, robustness becomes an evidentiary property of the scientific claim, demonstrated through figures that make scientific conclusion stable, explore how this other steps within the data science lifecycle integrate with robustness

::: footer

:::



